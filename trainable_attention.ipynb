{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teelch0/Data-Mining/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.weight\n",
        "inputs"
      ],
      "metadata": {
        "id": "oNX4cULRxBVk",
        "outputId": "d925eab7-b7fb-447e-fb32-efc101062ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oNX4cULRxBVk",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.2806,  0.4944,  0.4300,  0.0465,  1.4924,  0.2436, -1.0622, -0.4265],\n",
              "        [-2.4479, -1.0193, -0.2891,  0.4367,  1.2408, -0.8976, -1.7771, -1.0501],\n",
              "        [ 1.3180, -0.5762,  0.0250,  0.8471,  1.0583,  0.0349,  0.8652,  1.2088],\n",
              "        [ 0.2441, -1.5191,  0.0631,  0.8979, -0.9527,  2.3419,  1.3389, -0.2293]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.data\n",
        "inputs"
      ],
      "metadata": {
        "id": "sTBV2KZYxCLY",
        "outputId": "f60cbd52-8492-4a10-a274-7e7197cf50f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sTBV2KZYxCLY",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2806,  0.4944,  0.4300,  0.0465,  1.4924,  0.2436, -1.0622, -0.4265],\n",
              "        [-2.4479, -1.0193, -0.2891,  0.4367,  1.2408, -0.8976, -1.7771, -1.0501],\n",
              "        [ 1.3180, -0.5762,  0.0250,  0.8471,  1.0583,  0.0349,  0.8652,  1.2088],\n",
              "        [ 0.2441, -1.5191,  0.0631,  0.8979, -0.9527,  2.3419,  1.3389, -0.2293]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set dimensions\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
      ],
      "metadata": {
        "id": "QOwlthXbxb38"
      },
      "id": "QOwlthXbxb38",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose an input vector and transform it into our query vector using W_q\n",
        "query = inputs[2] @ W_q\n",
        "query"
      ],
      "metadata": {
        "id": "sNXSVRxtyUEq",
        "outputId": "1d3fa001-18b6-4353-825c-4a0ba56d1f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sNXSVRxtyUEq",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5024, 2.4207, 2.9022, 2.1201, 2.3435, 2.8275])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate attention scores using the keys generated by W_k:\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values )"
      ],
      "metadata": {
        "id": "krMfHBPty33R",
        "outputId": "a52e6ea2-439f-45fe-9eb7-9e1b8858fdac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "krMfHBPty33R",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: tensor([[-0.5073,  1.2651, -0.1021,  0.8676, -0.5303,  0.0434],\n",
            "        [-3.9572, -0.3074, -3.3211, -2.9162, -2.4289, -2.8603],\n",
            "        [ 3.3206,  1.5578,  2.4214,  2.4110,  2.3086,  3.4707],\n",
            "        [ 1.0083, -0.9660,  0.0181,  0.8910,  0.4738,  2.5151]])\n",
            "Values: tensor([[-3.5163e-01,  1.0783e-01, -3.1948e-01,  1.3662e+00, -2.8707e-03,\n",
            "          5.8443e-03],\n",
            "        [-2.1639e+00, -2.3352e+00, -3.9932e+00, -1.9737e+00, -3.2772e+00,\n",
            "         -3.0560e+00],\n",
            "        [ 2.9322e+00,  7.6027e-01,  2.1532e+00,  1.8534e+00,  1.5613e+00,\n",
            "          3.6199e+00],\n",
            "        [ 6.9703e-01,  5.8646e-01, -7.3323e-01,  1.0819e-01,  1.4628e+00,\n",
            "          5.2351e-02]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ],
      "metadata": {
        "id": "ZCYUxgufzYJx",
        "outputId": "2b910898-8dff-454c-a484-3b880ed07268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZCYUxgufzYJx",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2.7231, -36.2900,  36.1226,   9.3399])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "8E3nKiYMz-B3",
        "outputId": "00da9994-3278-476f-ee61-343732b3894f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8E3nKiYMz-B3",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1974e-06, 1.4496e-13, 9.9998e-01, 1.7841e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.sum()"
      ],
      "metadata": {
        "id": "ivp5ajUU0hVX",
        "outputId": "511356c9-21c6-4249-80a9-616d39e27315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ivp5ajUU0hVX",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ],
      "metadata": {
        "id": "NDyjIXnw01bw",
        "outputId": "77945d87-d273-440f-9940-6b06c22aa8c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NDyjIXnw01bw",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.9321, 0.7603, 2.1531, 1.8534, 1.5613, 3.6199])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "mDJu60I-08oe"
      },
      "id": "mDJu60I-08oe",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's a first version of a SimpleAttention class:\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = x @ self.W_q\n",
        "    keys = x @ self.W_k\n",
        "    values = x @ self.W_v\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "nCNgyvAjDqJx"
      },
      "id": "nCNgyvAjDqJx",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ],
      "metadata": {
        "id": "WGqfizBVGQ6H"
      },
      "id": "WGqfizBVGQ6H",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_v"
      ],
      "metadata": {
        "id": "m8khSsLLGbPx",
        "outputId": "0c2a4934-8588-4ac4-b22c-d55f866a7407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m8khSsLLGbPx",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.7293, 0.8502, 0.6565, 0.4199, 0.1735, 0.9826],\n",
              "        [0.3794, 0.2877, 0.7248, 0.0818, 0.8074, 0.6125],\n",
              "        [0.8329, 0.3381, 0.4947, 0.1881, 0.6524, 0.6146],\n",
              "        [0.1393, 0.7182, 0.7430, 0.3475, 0.9769, 0.4539],\n",
              "        [0.0665, 0.1510, 0.0243, 0.3057, 0.1000, 0.6977],\n",
              "        [0.5152, 0.1690, 0.9540, 0.0295, 0.7460, 0.0525],\n",
              "        [0.6649, 0.5394, 0.1135, 0.1347, 0.3084, 0.3127],\n",
              "        [0.2835, 0.2572, 0.6093, 0.0678, 0.2464, 0.7825]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "IDXEWBn2GhTu",
        "outputId": "bece8662-9db7-4588-9dcd-a0e9f6c52921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IDXEWBn2GhTu",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.7185,  1.8073,  1.8980,  0.7321,  1.4871,  1.2243],\n",
              "        [-4.2112, -3.3516, -3.8323, -0.9717, -2.3623, -3.5680],\n",
              "        [ 1.8876,  2.5140,  1.9831,  1.3276,  1.3042,  3.2954],\n",
              "        [ 1.8796,  2.4783,  1.9795,  1.2974,  1.3141,  3.1905]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here's a second version of a SimpleAttention class ;\n",
        "# it uses nn.Linear to do things more efficiently\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return weights"
      ],
      "metadata": {
        "id": "j0J4KZOZGqfu"
      },
      "id": "j0J4KZOZGqfu",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ],
      "metadata": {
        "id": "Zki5jtLCI6Cu"
      },
      "id": "Zki5jtLCI6Cu",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "k6LcTWL9I8te",
        "outputId": "0a996b2e-e761-4ebb-bf0f-3bbb85ce25ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k6LcTWL9I8te",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2009, 0.1474, 0.3745, 0.2772],\n",
              "        [0.1809, 0.1300, 0.3843, 0.3048],\n",
              "        [0.2137, 0.2182, 0.1984, 0.3697],\n",
              "        [0.2475, 0.3959, 0.1855, 0.1711]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
        "# in practice, we should only use information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ],
      "metadata": {
        "id": "oue7IwuyI_ON"
      },
      "id": "oue7IwuyI_ON",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a hack to get some example weights to work with!\n",
        "weights = simple( inputs )\n",
        "weights"
      ],
      "metadata": {
        "id": "L734IABHc89l",
        "outputId": "d8530826-b6cf-4a8c-902c-103442c6bb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L734IABHc89l",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2009, 0.1474, 0.3745, 0.2772],\n",
              "        [0.1809, 0.1300, 0.3843, 0.3048],\n",
              "        [0.2137, 0.2182, 0.1984, 0.3697],\n",
              "        [0.2475, 0.3959, 0.1855, 0.1711]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that these have already been normalized:\n",
        "weights.sum( dim=-1 )"
      ],
      "metadata": {
        "id": "SiNiJA_tdnIr",
        "outputId": "6f1788d6-ff24-4072-ad98-be5478e78a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SiNiJA_tdnIr",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2787, 1.4662, 1.1613, 1.2218], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking method #1\n",
        "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
        "simple_mask"
      ],
      "metadata": {
        "id": "w8qwVBb3d5YE",
        "outputId": "e248b65e-7e64-475e-ae2a-4526879d5515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w8qwVBb3d5YE",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = weights*simple_mask\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "aPN1GiEdeWq_",
        "outputId": "4fd15413-ce2c-4031-8bb6-7cd17b6607e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aPN1GiEdeWq_",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2009, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1809, 0.1300, 0.0000, 0.0000],\n",
              "        [0.2137, 0.2182, 0.1984, 0.0000],\n",
              "        [0.2475, 0.3959, 0.1855, 0.1711]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights.sum( dim=-1 )"
      ],
      "metadata": {
        "id": "N-Ifwx0EfJs9",
        "outputId": "0bdaf7cb-34c3-4d77-e7ca-45eae88ca0ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N-Ifwx0EfJs9",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2009, 0.3109, 0.6303, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we need to normalize the masked_weights so that each row has sum 1\n",
        "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
        "row_sums"
      ],
      "metadata": {
        "id": "gbOrqXGSfbm2",
        "outputId": "3f940c1f-e6c6-47dc-8fb4-ac4230d69fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gbOrqXGSfbm2",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2009],\n",
              "        [0.3109],\n",
              "        [0.6303],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = masked_weights / row_sums\n",
        "masked_weights.sum( dim=-1)"
      ],
      "metadata": {
        "id": "ACdob5jyfi2P",
        "outputId": "43e569ad-df2b-4de8-fba4-265ada27e05c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ACdob5jyfi2P",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights"
      ],
      "metadata": {
        "id": "0_aQEYcQf4tB",
        "outputId": "b2f6d9c8-d301-4361-d0fc-d77a3de0dec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0_aQEYcQf4tB",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5820, 0.4180, 0.0000, 0.0000],\n",
              "        [0.3391, 0.3462, 0.3147, 0.0000],\n",
              "        [0.2475, 0.3959, 0.1855, 0.1711]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking method #2\n",
        "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "mask"
      ],
      "metadata": {
        "id": "QxaUROkpgBmr",
        "outputId": "f6b9524f-e341-4c78-824d-d07fe213948b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QxaUROkpgBmr",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.bool()"
      ],
      "metadata": {
        "id": "9aAkggNUhUAs",
        "outputId": "605eaecc-a9b7-4cdb-df3e-3d2ac460517a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9aAkggNUhUAs",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "id": "84ev4pTZhoLD",
        "outputId": "16740412-1071-4a47-e0bf-6bc2f668b37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "84ev4pTZhoLD",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2009, 0.1474, 0.3745, 0.2772],\n",
              "        [0.1809, 0.1300, 0.3843, 0.3048],\n",
              "        [0.2137, 0.2182, 0.1984, 0.3697],\n",
              "        [0.2475, 0.3959, 0.1855, 0.1711]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
        "weights"
      ],
      "metadata": {
        "id": "7AW_dLvCgiA8",
        "outputId": "69a0f8e6-dd5a-4df2-be6f-762280aa9722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7AW_dLvCgiA8",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2009,   -inf,   -inf,   -inf],\n",
              "        [0.1809, 0.1300,   -inf,   -inf],\n",
              "        [0.2137, 0.2182, 0.1984,   -inf],\n",
              "        [0.2475, 0.3959, 0.1855, 0.1711]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = torch.softmax( weights, dim=-1 )\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "mMquJ-g1hvuq",
        "outputId": "70354832-0b25-4904-e4c5-8f698b4fcc81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mMquJ-g1hvuq",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5127, 0.4873, 0.0000, 0.0000],\n",
              "        [0.3345, 0.3360, 0.3294, 0.0000],\n",
              "        [0.2484, 0.2881, 0.2334, 0.2301]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropout\n",
        "# idea: randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout( 0.5 )"
      ],
      "metadata": {
        "id": "v0Rl7yaikQwW"
      },
      "id": "v0Rl7yaikQwW",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout( masked_weights )"
      ],
      "metadata": {
        "id": "Js4JQ6b9lN1p",
        "outputId": "4963cceb-5060-4ecf-cdcf-3c3eddfc12b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Js4JQ6b9lN1p",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.6589, 0.0000],\n",
              "        [0.0000, 0.5762, 0.0000, 0.0000]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack( (inputs, inputs), dim=0)"
      ],
      "metadata": {
        "id": "lwzL1olBjA62"
      },
      "id": "lwzL1olBjA62",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches.shape"
      ],
      "metadata": {
        "id": "F9pE07dKjkPS",
        "outputId": "169510b7-27e1-4509-8a52-2926e4dfd456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F9pE07dKjkPS",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.dropout = Dropout( dropout )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "uP2PuQ5RiCM8"
      },
      "id": "uP2PuQ5RiCM8",
      "execution_count": 73,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teelch0/Data-Mining/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.weight\n",
        "inputs"
      ],
      "metadata": {
        "id": "oNX4cULRxBVk",
        "outputId": "23cbf7a2-c9b9-41e1-bc22-e84893e8bcbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oNX4cULRxBVk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.5144, -0.2876, -0.5925,  0.6853, -1.4830,  1.1301,  0.5501,  0.8885],\n",
              "        [-1.0101, -0.8224,  2.7662,  1.2267, -0.6145,  0.0572, -0.7568,  0.6611],\n",
              "        [ 1.6995, -0.3372, -1.7805,  0.3423, -0.3928,  0.2949,  0.7520,  0.8136],\n",
              "        [-0.3884, -1.6392, -0.8317, -1.4207, -0.1643, -0.4159, -1.9173,  0.2474]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.data\n",
        "inputs"
      ],
      "metadata": {
        "id": "sTBV2KZYxCLY",
        "outputId": "3ba69803-6b3e-4a5f-ca6f-081e4dc86652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sTBV2KZYxCLY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5144, -0.2876, -0.5925,  0.6853, -1.4830,  1.1301,  0.5501,  0.8885],\n",
              "        [-1.0101, -0.8224,  2.7662,  1.2267, -0.6145,  0.0572, -0.7568,  0.6611],\n",
              "        [ 1.6995, -0.3372, -1.7805,  0.3423, -0.3928,  0.2949,  0.7520,  0.8136],\n",
              "        [-0.3884, -1.6392, -0.8317, -1.4207, -0.1643, -0.4159, -1.9173,  0.2474]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set dimensions\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
      ],
      "metadata": {
        "id": "QOwlthXbxb38"
      },
      "id": "QOwlthXbxb38",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose an input vector and transform it into our query vector using W_q\n",
        "query = inputs[2] @ W_q\n",
        "query"
      ],
      "metadata": {
        "id": "sNXSVRxtyUEq",
        "outputId": "9fcf5864-bd06-4dcd-c40d-f44f066cbb2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sNXSVRxtyUEq",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2240,  1.3947, -0.6227,  0.1006, -0.4559, -0.2327])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate attention scores using the keys generated by W_k:\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values )"
      ],
      "metadata": {
        "id": "krMfHBPty33R",
        "outputId": "8cc3fd0c-878d-4ff9-9c65-6dec36fd2288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "krMfHBPty33R",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: tensor([[ 0.4340, -0.4435,  0.4869, -0.9997, -0.1238, -0.4004],\n",
            "        [ 1.3744, -0.2518,  1.2144, -0.3979, -0.8276, -0.6358],\n",
            "        [-0.4079,  1.1825,  0.7480, -0.0312,  1.5904,  0.8623],\n",
            "        [-4.3143, -3.2547, -4.3417, -2.8424, -2.8922, -2.9691]])\n",
            "Values: tensor([[ 0.2843,  0.5977, -0.1439, -1.5276,  0.3573, -0.4165],\n",
            "        [-0.2346,  0.0294,  0.8861,  0.2544,  2.3080,  1.7589],\n",
            "        [ 1.5109,  2.1382, -0.1074, -0.2093, -0.0315, -1.0489],\n",
            "        [-4.7379, -4.7088, -2.3949, -1.8229, -2.1963, -2.1774]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ],
      "metadata": {
        "id": "ZCYUxgufzYJx",
        "outputId": "9b983037-7583-45f9-9d06-ce45fb08c2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZCYUxgufzYJx",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7755, -0.3143,  0.1631, -1.0785])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "8E3nKiYMz-B3",
        "outputId": "602dc261-23d8-46bc-e26b-176cfd2500be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8E3nKiYMz-B3",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2194, 0.2649, 0.3219, 0.1939])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.sum()"
      ],
      "metadata": {
        "id": "ivp5ajUU0hVX",
        "outputId": "5fb92e90-4516-48c6-b0ac-74a26b2dc2fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ivp5ajUU0hVX",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ],
      "metadata": {
        "id": "NDyjIXnw01bw",
        "outputId": "0a47f27b-0cb2-4f2a-e709-be184b040440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NDyjIXnw01bw",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4321, -0.0858, -0.2958, -0.6886,  0.2537, -0.3853])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "mDJu60I-08oe"
      },
      "id": "mDJu60I-08oe",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's a first version of a SimpleAttention class:\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = x @ self.W_q\n",
        "    keys = x @ self.W_k\n",
        "    values = x @ self.W_v\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "nCNgyvAjDqJx"
      },
      "id": "nCNgyvAjDqJx",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ],
      "metadata": {
        "id": "WGqfizBVGQ6H"
      },
      "id": "WGqfizBVGQ6H",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_v"
      ],
      "metadata": {
        "id": "m8khSsLLGbPx",
        "outputId": "5c92bed3-12db-40d5-e505-a2e1fd83dddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m8khSsLLGbPx",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.4713, 0.5174, 0.5561, 0.6869, 0.9157, 0.6996],\n",
              "        [0.7924, 0.2744, 0.8399, 0.3575, 0.8785, 0.7665],\n",
              "        [0.8209, 0.9577, 0.6348, 0.1826, 0.4509, 0.0427],\n",
              "        [0.9900, 0.1020, 0.5539, 0.4737, 0.0176, 0.2476],\n",
              "        [0.0241, 0.5900, 0.3420, 0.5407, 0.4753, 0.4030],\n",
              "        [0.8273, 0.3048, 0.5215, 0.7960, 0.2324, 0.8107],\n",
              "        [0.7775, 0.3525, 0.7343, 0.3644, 0.5825, 0.1267],\n",
              "        [0.2497, 0.5370, 0.7109, 0.1379, 0.9974, 0.4581]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "IDXEWBn2GhTu",
        "outputId": "ba479139-23c0-47d6-d85d-d24f5d6ed0ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IDXEWBn2GhTu",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0183, -0.3816, -0.1456, -0.1467, -0.2976, -0.0868],\n",
              "        [ 1.6009,  1.0210,  0.8057, -0.0985, -0.1908, -0.4073],\n",
              "        [ 0.8315, -0.2106,  0.7974,  0.8025,  0.8686,  0.9164],\n",
              "        [-5.3481, -2.3589, -4.4127, -2.7622, -3.2405, -2.4485]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here's a second version of a SimpleAttention class ;\n",
        "# it uses nn.Linear to do things more efficiently\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return weights"
      ],
      "metadata": {
        "id": "j0J4KZOZGqfu"
      },
      "id": "j0J4KZOZGqfu",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ],
      "metadata": {
        "id": "Zki5jtLCI6Cu"
      },
      "id": "Zki5jtLCI6Cu",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "k6LcTWL9I8te",
        "outputId": "fa0c01c0-2c99-426d-b875-914340bc71d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k6LcTWL9I8te",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2056, 0.2703, 0.2361, 0.2880],\n",
              "        [0.1612, 0.4250, 0.1154, 0.2984],\n",
              "        [0.2681, 0.1686, 0.2787, 0.2845],\n",
              "        [0.1823, 0.2210, 0.1754, 0.4213]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
        "# in practice, we should only use information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ],
      "metadata": {
        "id": "oue7IwuyI_ON"
      },
      "id": "oue7IwuyI_ON",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a hack to get some example weights to work with!\n",
        "weights = simple( inputs )\n",
        "weights"
      ],
      "metadata": {
        "id": "L734IABHc89l",
        "outputId": "2bb3c2c2-381a-4a5e-be74-c77a23729584",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L734IABHc89l",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2056, 0.2703, 0.2361, 0.2880],\n",
              "        [0.1612, 0.4250, 0.1154, 0.2984],\n",
              "        [0.2681, 0.1686, 0.2787, 0.2845],\n",
              "        [0.1823, 0.2210, 0.1754, 0.4213]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that these have already been normalized:\n",
        "weights.sum( dim=-1 )"
      ],
      "metadata": {
        "id": "SiNiJA_tdnIr",
        "outputId": "d0650bf1-11d3-4172-cbd0-1d6dfddb9646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SiNiJA_tdnIr",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking method #1\n",
        "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
        "simple_mask"
      ],
      "metadata": {
        "id": "w8qwVBb3d5YE",
        "outputId": "868d3fb8-6781-4ceb-ca5e-96207f6773a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w8qwVBb3d5YE",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = weights*simple_mask\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "aPN1GiEdeWq_",
        "outputId": "8996d910-3c84-4e5a-fec3-92c891557bf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aPN1GiEdeWq_",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2056, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1612, 0.4250, 0.0000, 0.0000],\n",
              "        [0.2681, 0.1686, 0.2787, 0.0000],\n",
              "        [0.1823, 0.2210, 0.1754, 0.4213]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights.sum( dim=-1 )"
      ],
      "metadata": {
        "id": "N-Ifwx0EfJs9",
        "outputId": "ef00b13a-835b-408f-ad30-3134b177350b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N-Ifwx0EfJs9",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2056, 0.5862, 0.7155, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we need to normalize the masked_weights so that each row has sum 1\n",
        "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
        "row_sums"
      ],
      "metadata": {
        "id": "gbOrqXGSfbm2",
        "outputId": "9ef9ce06-92d7-430d-cd76-ae6d5bda446b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gbOrqXGSfbm2",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2056],\n",
              "        [0.5862],\n",
              "        [0.7155],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = masked_weights / row_sums\n",
        "masked_weights.sum( dim=-1)"
      ],
      "metadata": {
        "id": "ACdob5jyfi2P",
        "outputId": "ae2e5136-eb61-457f-da88-fcd365b8142a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ACdob5jyfi2P",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights"
      ],
      "metadata": {
        "id": "0_aQEYcQf4tB",
        "outputId": "d2afe92d-2f35-48ce-ee84-15c80a495ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0_aQEYcQf4tB",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2750, 0.7250, 0.0000, 0.0000],\n",
              "        [0.3748, 0.2356, 0.3896, 0.0000],\n",
              "        [0.1823, 0.2210, 0.1754, 0.4213]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking method #2\n",
        "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "mask"
      ],
      "metadata": {
        "id": "QxaUROkpgBmr",
        "outputId": "14a280bf-865b-4e81-d8cb-d941a0cba9a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QxaUROkpgBmr",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.bool()"
      ],
      "metadata": {
        "id": "9aAkggNUhUAs",
        "outputId": "e7d1f21c-c66a-4b6d-90d2-c24c010297cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9aAkggNUhUAs",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "id": "84ev4pTZhoLD",
        "outputId": "c7ee5bc5-e463-4c52-840e-4fdd9de96634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "84ev4pTZhoLD",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2056, 0.2703, 0.2361, 0.2880],\n",
              "        [0.1612, 0.4250, 0.1154, 0.2984],\n",
              "        [0.2681, 0.1686, 0.2787, 0.2845],\n",
              "        [0.1823, 0.2210, 0.1754, 0.4213]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
        "weights"
      ],
      "metadata": {
        "id": "7AW_dLvCgiA8",
        "outputId": "79f541f1-8c2b-49a9-ebee-97b712515585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7AW_dLvCgiA8",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2056,   -inf,   -inf,   -inf],\n",
              "        [0.1612, 0.4250,   -inf,   -inf],\n",
              "        [0.2681, 0.1686, 0.2787,   -inf],\n",
              "        [0.1823, 0.2210, 0.1754, 0.4213]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = torch.softmax( weights, dim=-1 )\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "mMquJ-g1hvuq",
        "outputId": "fccdaa0d-41ae-4e0c-cfe6-4a9be60eafe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mMquJ-g1hvuq",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4344, 0.5656, 0.0000, 0.0000],\n",
              "        [0.3429, 0.3104, 0.3466, 0.0000],\n",
              "        [0.2324, 0.2416, 0.2308, 0.2952]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropout\n",
        "# idea: randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout( 0.5 )"
      ],
      "metadata": {
        "id": "v0Rl7yaikQwW"
      },
      "id": "v0Rl7yaikQwW",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout( masked_weights )"
      ],
      "metadata": {
        "id": "Js4JQ6b9lN1p",
        "outputId": "1f493805-c468-4fb9-cce6-2ec8058a354c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Js4JQ6b9lN1p",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.6859, 0.6209, 0.6932, 0.0000],\n",
              "        [0.4649, 0.4832, 0.4616, 0.0000]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack( (inputs, inputs), dim=0)"
      ],
      "metadata": {
        "id": "lwzL1olBjA62"
      },
      "id": "lwzL1olBjA62",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches"
      ],
      "metadata": {
        "id": "F9pE07dKjkPS",
        "outputId": "a9211cb8-dc30-4156-ae78-1a2ea721bf6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F9pE07dKjkPS",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5144, -0.2876, -0.5925,  0.6853, -1.4830,  1.1301,  0.5501,\n",
              "           0.8885],\n",
              "         [-1.0101, -0.8224,  2.7662,  1.2267, -0.6145,  0.0572, -0.7568,\n",
              "           0.6611],\n",
              "         [ 1.6995, -0.3372, -1.7805,  0.3423, -0.3928,  0.2949,  0.7520,\n",
              "           0.8136],\n",
              "         [-0.3884, -1.6392, -0.8317, -1.4207, -0.1643, -0.4159, -1.9173,\n",
              "           0.2474]],\n",
              "\n",
              "        [[-0.5144, -0.2876, -0.5925,  0.6853, -1.4830,  1.1301,  0.5501,\n",
              "           0.8885],\n",
              "         [-1.0101, -0.8224,  2.7662,  1.2267, -0.6145,  0.0572, -0.7568,\n",
              "           0.6611],\n",
              "         [ 1.6995, -0.3372, -1.7805,  0.3423, -0.3928,  0.2949,  0.7520,\n",
              "           0.8136],\n",
              "         [-0.3884, -1.6392, -0.8317, -1.4207, -0.1643, -0.4159, -1.9173,\n",
              "           0.2474]]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.dropout = nn.Dropout( dropout ) #include dropout\n",
        "    self.register_buffer(#use to manage memory efficiently\n",
        "        'mask',\n",
        "        torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "    )\n",
        "\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.transpose(1,2)\n",
        "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "uP2PuQ5RiCM8"
      },
      "id": "uP2PuQ5RiCM8",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0)\n",
        "#instantiate a causal attention mechanism"
      ],
      "metadata": {
        "id": "HSBRFNZA0dqF"
      },
      "id": "HSBRFNZA0dqF",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "causal(batches)"
      ],
      "metadata": {
        "id": "VyvSLkcE4tR_",
        "outputId": "44480b61-bb42-4b59-b943-e68980203e2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VyvSLkcE4tR_",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3222,  0.0286,  1.0227,  0.0562,  0.5668,  0.6717],\n",
              "         [-0.4803,  0.3176,  0.6440,  0.3903,  0.3554, -0.1116],\n",
              "         [-0.4202,  0.1089,  0.5496,  0.1852,  0.3861,  0.0888],\n",
              "         [-0.2863, -0.0042,  0.3866, -0.0514,  0.4464,  0.3881]],\n",
              "\n",
              "        [[-0.3222,  0.0286,  1.0227,  0.0562,  0.5668,  0.6717],\n",
              "         [-0.4803,  0.3176,  0.6440,  0.3903,  0.3554, -0.1116],\n",
              "         [-0.4202,  0.1089,  0.5496,  0.1852,  0.3861,  0.0888],\n",
              "         [-0.2863, -0.0042,  0.3866, -0.0514,  0.4464,  0.3881]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "W_v = nn.Linear( d_in, d_out, bias=False )"
      ],
      "metadata": {
        "id": "f6z9xNOi09qx"
      },
      "id": "f6z9xNOi09qx",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries= W_q( batches )\n",
        "queries"
      ],
      "metadata": {
        "id": "Bei_zf5O1NY7",
        "outputId": "4401c889-2706-45d8-a8cb-80ab6b034e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Bei_zf5O1NY7",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1981,  0.6930, -0.5793,  0.3826,  0.0747, -0.0669],\n",
              "         [ 0.3678, -0.1562, -0.3005, -0.8592, -0.4347, -0.0084],\n",
              "         [ 0.3455,  0.3496, -0.5403,  0.4469,  0.8124, -0.4717],\n",
              "         [-1.0737, -0.9779,  0.6552, -0.3107,  0.4692, -0.4736]],\n",
              "\n",
              "        [[ 0.1981,  0.6930, -0.5793,  0.3826,  0.0747, -0.0669],\n",
              "         [ 0.3678, -0.1562, -0.3005, -0.8592, -0.4347, -0.0084],\n",
              "         [ 0.3455,  0.3496, -0.5403,  0.4469,  0.8124, -0.4717],\n",
              "         [-1.0737, -0.9779,  0.6552, -0.3107,  0.4692, -0.4736]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys= W_k( batches )\n",
        "keys"
      ],
      "metadata": {
        "id": "32Ac7rgV1ivq",
        "outputId": "09d8fa46-fcaa-4326-d2bf-2d5a0719d6e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "32Ac7rgV1ivq",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7103,  0.7806, -0.4968, -0.9811,  0.5417, -0.0483],\n",
              "         [-0.8315, -0.1817,  0.5227,  0.5549, -0.6145,  0.5099],\n",
              "         [ 0.3417,  0.9014, -0.3325, -0.9042,  0.4625, -0.6542],\n",
              "         [-0.4073, -0.1351, -0.6780,  0.5060,  0.2485,  0.1818]],\n",
              "\n",
              "        [[ 0.7103,  0.7806, -0.4968, -0.9811,  0.5417, -0.0483],\n",
              "         [-0.8315, -0.1817,  0.5227,  0.5549, -0.6145,  0.5099],\n",
              "         [ 0.3417,  0.9014, -0.3325, -0.9042,  0.4625, -0.6542],\n",
              "         [-0.4073, -0.1351, -0.6780,  0.5060,  0.2485,  0.1818]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys.transpose(1,2)"
      ],
      "metadata": {
        "id": "YWDQyykB2KWk",
        "outputId": "6af7e0d2-baa6-4ea8-8001-02edcb1eecfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YWDQyykB2KWk",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7103, -0.8315,  0.3417, -0.4073],\n",
              "         [ 0.7806, -0.1817,  0.9014, -0.1351],\n",
              "         [-0.4968,  0.5227, -0.3325, -0.6780],\n",
              "         [-0.9811,  0.5549, -0.9042,  0.5060],\n",
              "         [ 0.5417, -0.6145,  0.4625,  0.2485],\n",
              "         [-0.0483,  0.5099, -0.6542,  0.1818]],\n",
              "\n",
              "        [[ 0.7103, -0.8315,  0.3417, -0.4073],\n",
              "         [ 0.7806, -0.1817,  0.9014, -0.1351],\n",
              "         [-0.4968,  0.5227, -0.3325, -0.6780],\n",
              "         [-0.9811,  0.5549, -0.9042,  0.5060],\n",
              "         [ 0.5417, -0.6145,  0.4625,  0.2485],\n",
              "         [-0.0483,  0.5099, -0.6542,  0.1818]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi-head attention\n",
        "#multiple causal attentions stuck together\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat( [ head(x) for head in self.heads], dim= -1)\n"
      ],
      "metadata": {
        "id": "3sSNiBJUfCzu"
      },
      "id": "3sSNiBJUfCzu",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention( d_in = 8, d_out = 6, context_length = 4, dropout = 0, num_heads = 3)"
      ],
      "metadata": {
        "id": "txjaGgYCii-y"
      },
      "id": "txjaGgYCii-y",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out = mha(batches)"
      ],
      "metadata": {
        "id": "PLdd3ux1ijd6"
      },
      "id": "PLdd3ux1ijd6",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out"
      ],
      "metadata": {
        "id": "xrTwTb_OijiN",
        "outputId": "96fb4ee4-ae1c-4b95-9a87-0c8646d37a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xrTwTb_OijiN",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.7469e-01,  1.2094e+00, -4.5389e-02,  3.8637e-01, -4.3214e-01,\n",
              "           6.6472e-01, -2.3259e-01, -3.2051e-01, -4.5996e-01,  1.8837e-01,\n",
              "           1.7489e-01,  4.7684e-01, -3.2374e-01,  1.1922e-01,  9.7719e-02,\n",
              "           6.8529e-01,  5.3678e-02,  5.9794e-01],\n",
              "         [ 1.1060e-02,  9.0605e-01, -2.8432e-01, -1.1351e-01,  9.9134e-02,\n",
              "           4.7537e-01, -2.6532e-02, -2.8162e-01, -4.0482e-02, -2.5999e-01,\n",
              "           3.0705e-01, -2.9023e-01, -2.2019e-01,  3.7587e-01,  2.5520e-01,\n",
              "           4.8670e-01,  1.2887e-01,  3.4912e-01],\n",
              "         [ 1.5671e-01,  7.2261e-01, -2.6303e-01,  9.4548e-02, -1.4341e-02,\n",
              "           4.4316e-01,  2.3497e-02, -2.1352e-01,  3.1542e-02, -2.9462e-01,\n",
              "           2.9261e-01, -3.6400e-01,  1.6516e-02, -6.3373e-02, -2.0408e-01,\n",
              "           1.2524e-01,  2.2403e-02,  5.2884e-02],\n",
              "         [ 1.2673e-01,  4.3821e-01, -1.9526e-01,  7.7893e-02, -5.5941e-02,\n",
              "           3.6452e-01, -1.7185e-01, -2.2007e-01, -2.5148e-01,  1.3783e-01,\n",
              "           2.6300e-02,  2.1830e-02,  8.7987e-02,  7.8494e-02, -2.1046e-02,\n",
              "           5.7169e-02,  2.5682e-01, -7.3206e-04]],\n",
              "\n",
              "        [[ 1.7469e-01,  1.2094e+00, -4.5389e-02,  3.8637e-01, -4.3214e-01,\n",
              "           6.6472e-01, -2.3259e-01, -3.2051e-01, -4.5996e-01,  1.8837e-01,\n",
              "           1.7489e-01,  4.7684e-01, -3.2374e-01,  1.1922e-01,  9.7719e-02,\n",
              "           6.8529e-01,  5.3678e-02,  5.9794e-01],\n",
              "         [ 1.1060e-02,  9.0605e-01, -2.8432e-01, -1.1351e-01,  9.9134e-02,\n",
              "           4.7537e-01, -2.6532e-02, -2.8162e-01, -4.0482e-02, -2.5999e-01,\n",
              "           3.0705e-01, -2.9023e-01, -2.2019e-01,  3.7587e-01,  2.5520e-01,\n",
              "           4.8670e-01,  1.2887e-01,  3.4912e-01],\n",
              "         [ 1.5671e-01,  7.2261e-01, -2.6303e-01,  9.4548e-02, -1.4341e-02,\n",
              "           4.4316e-01,  2.3497e-02, -2.1352e-01,  3.1542e-02, -2.9462e-01,\n",
              "           2.9261e-01, -3.6400e-01,  1.6516e-02, -6.3373e-02, -2.0408e-01,\n",
              "           1.2524e-01,  2.2403e-02,  5.2884e-02],\n",
              "         [ 1.2673e-01,  4.3821e-01, -1.9526e-01,  7.7893e-02, -5.5941e-02,\n",
              "           3.6452e-01, -1.7185e-01, -2.2007e-01, -2.5148e-01,  1.3783e-01,\n",
              "           2.6300e-02,  2.1830e-02,  8.7987e-02,  7.8494e-02, -2.1046e-02,\n",
              "           5.7169e-02,  2.5682e-01, -7.3206e-04]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out.shape"
      ],
      "metadata": {
        "id": "ZkOewohro4Z5",
        "outputId": "f1b6388e-7069-4646-cd86-da8d94960295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZkOewohro4Z5",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`,\n",
        "        # this will result in errors in the mask creation further below.\n",
        "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
        "        # do not exceed `context_length` before reaching this forward method.\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "mKGBdMBzpg3k"
      },
      "id": "mKGBdMBzpg3k",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches.shape"
      ],
      "metadata": {
        "id": "AYoLiPacpjTg",
        "outputId": "6ab65622-e306-4b8c-a975-0dc2b54adf6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AYoLiPacpjTg",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches"
      ],
      "metadata": {
        "id": "0J91z7uSpm0_",
        "outputId": "4853777d-7973-4f24-aa5e-2d20c8343269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0J91z7uSpm0_",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5144, -0.2876, -0.5925,  0.6853, -1.4830,  1.1301,  0.5501,\n",
              "           0.8885],\n",
              "         [-1.0101, -0.8224,  2.7662,  1.2267, -0.6145,  0.0572, -0.7568,\n",
              "           0.6611],\n",
              "         [ 1.6995, -0.3372, -1.7805,  0.3423, -0.3928,  0.2949,  0.7520,\n",
              "           0.8136],\n",
              "         [-0.3884, -1.6392, -0.8317, -1.4207, -0.1643, -0.4159, -1.9173,\n",
              "           0.2474]],\n",
              "\n",
              "        [[-0.5144, -0.2876, -0.5925,  0.6853, -1.4830,  1.1301,  0.5501,\n",
              "           0.8885],\n",
              "         [-1.0101, -0.8224,  2.7662,  1.2267, -0.6145,  0.0572, -0.7568,\n",
              "           0.6611],\n",
              "         [ 1.6995, -0.3372, -1.7805,  0.3423, -0.3928,  0.2949,  0.7520,\n",
              "           0.8136],\n",
              "         [-0.3884, -1.6392, -0.8317, -1.4207, -0.1643, -0.4159, -1.9173,\n",
              "           0.2474]]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches.view(2, 4, 2, 4)"
      ],
      "metadata": {
        "id": "GGr8Ool6poAB",
        "outputId": "f16c05ce-5e71-45c1-c00e-bd8c87961a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GGr8Ool6poAB",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.5144, -0.2876, -0.5925,  0.6853],\n",
              "          [-1.4830,  1.1301,  0.5501,  0.8885]],\n",
              "\n",
              "         [[-1.0101, -0.8224,  2.7662,  1.2267],\n",
              "          [-0.6145,  0.0572, -0.7568,  0.6611]],\n",
              "\n",
              "         [[ 1.6995, -0.3372, -1.7805,  0.3423],\n",
              "          [-0.3928,  0.2949,  0.7520,  0.8136]],\n",
              "\n",
              "         [[-0.3884, -1.6392, -0.8317, -1.4207],\n",
              "          [-0.1643, -0.4159, -1.9173,  0.2474]]],\n",
              "\n",
              "\n",
              "        [[[-0.5144, -0.2876, -0.5925,  0.6853],\n",
              "          [-1.4830,  1.1301,  0.5501,  0.8885]],\n",
              "\n",
              "         [[-1.0101, -0.8224,  2.7662,  1.2267],\n",
              "          [-0.6145,  0.0572, -0.7568,  0.6611]],\n",
              "\n",
              "         [[ 1.6995, -0.3372, -1.7805,  0.3423],\n",
              "          [-0.3928,  0.2949,  0.7520,  0.8136]],\n",
              "\n",
              "         [[-0.3884, -1.6392, -0.8317, -1.4207],\n",
              "          [-0.1643, -0.4159, -1.9173,  0.2474]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention( d_in = 8, d_out = 6, context_length=4, dropout=0, num_heads=3 )"
      ],
      "metadata": {
        "id": "qvlmgSDnp6KF"
      },
      "id": "qvlmgSDnp6KF",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out= mha(batches)"
      ],
      "metadata": {
        "id": "ZGbVvtARp_p5"
      },
      "id": "ZGbVvtARp_p5",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out.shape"
      ],
      "metadata": {
        "id": "SPCEPVafqGIF",
        "outputId": "a4b4b593-5a0b-462d-f8be-1545d17c48f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SPCEPVafqGIF",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
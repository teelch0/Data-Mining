{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a577d280",
      "metadata": {
        "id": "a577d280"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "57edbbb3",
      "metadata": {
        "id": "57edbbb3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`,\n",
        "        # this will result in errors in the mask creation further below.\n",
        "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
        "        # do not exceed `context_length` before reaching this forward method.\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TransformerBlock( nn.Module ):\n",
        "    def __init__( self, cfg ):\n",
        "        super().__init__()\n",
        "        self.norm1 = LayerNorm( cfg[\"emb_dim\"] )\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in = cfg[\"emb_dim\"],\n",
        "            d_out = cfg[\"emb_dim\"],\n",
        "            context_length = cfg[\"context_length\"],\n",
        "            dropout = cfg[\"drop_rate\"],\n",
        "            num_heads = cfg[\"n_heads\"]\n",
        "        )\n",
        "        self.dropout = nn.Dropout( cfg[\"drop_rate\"] )\n",
        "        self.norm2 = LayerNorm( cfg[\"emb_dim\"] )\n",
        "        self.feedforward = FeedForward( cfg )\n",
        "\n",
        "    def forward( self, x ):\n",
        "\n",
        "        # the attention chunk in this transformer:\n",
        "        shortcut = x\n",
        "        x = self.norm1( x )\n",
        "        x = self.att( x )\n",
        "        x = self.dropout( x )\n",
        "        x = x + shortcut\n",
        "\n",
        "        # the feed forward chunk:\n",
        "        shortcut = x\n",
        "        x = self.norm2( x )\n",
        "        x = self.feedforward( x )\n",
        "        x = self.dropout( x )\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4320c466",
      "metadata": {
        "id": "4320c466"
      },
      "outputs": [],
      "source": [
        "# to make training faster on a laptop, change context_length as shown:\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 256,  # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "16b5282b",
      "metadata": {
        "id": "16b5282b"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "744511e5",
      "metadata": {
        "id": "744511e5"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f26be878",
      "metadata": {
        "id": "f26be878"
      },
      "outputs": [],
      "source": [
        "start_context = \"Every effort moves you\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1eceda77",
      "metadata": {
        "id": "1eceda77",
        "outputId": "45329e46-8c90-426b-a2c1-b19211055e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you severaliosis analyzed adolescents CAN infusedORKwav conception ES\n"
          ]
        }
      ],
      "source": [
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3d589e6b",
      "metadata": {
        "id": "3d589e6b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you forward\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c3366315",
      "metadata": {
        "id": "c3366315",
        "outputId": "be98ccff-2cd3-4ad8-f5c4-980201c0dbc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probs = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
        "print(probs.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "016d2404",
      "metadata": {
        "id": "016d2404",
        "outputId": "742007fa-459b-48b6-93f6-c9270c882496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[8.8013e-06, 2.2500e-05, 1.7316e-05,  ..., 4.4169e-05,\n",
              "          4.5220e-05, 8.8676e-06],\n",
              "         [1.8457e-05, 1.7507e-05, 2.0480e-05,  ..., 1.6346e-05,\n",
              "          2.5723e-05, 3.9376e-05],\n",
              "         [2.8503e-05, 1.2532e-05, 1.0338e-05,  ..., 9.6377e-06,\n",
              "          3.5955e-05, 2.1967e-05]],\n",
              "\n",
              "        [[2.3496e-05, 1.3199e-05, 1.8774e-05,  ..., 4.7985e-05,\n",
              "          4.1013e-05, 1.9856e-05],\n",
              "         [3.0057e-05, 3.5412e-05, 1.8609e-05,  ..., 1.4002e-05,\n",
              "          1.4240e-05, 7.9319e-05],\n",
              "         [1.2669e-05, 4.7169e-06, 1.2916e-05,  ..., 5.9913e-06,\n",
              "          1.2593e-05, 2.3162e-05]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "02286211",
      "metadata": {
        "id": "02286211",
        "outputId": "1a617146-8931-4854-9940-514cf511d61c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[23117],\n",
            "         [38207],\n",
            "         [21504]],\n",
            "\n",
            "        [[29332],\n",
            "         [46969],\n",
            "         [12144]]])\n"
          ]
        }
      ],
      "source": [
        "# predicted tokens:\n",
        "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c1c5fe54",
      "metadata": {
        "id": "c1c5fe54",
        "outputId": "9d0a0581-49e2-457e-f711-9aed1fce9c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1: abl dances mi\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e208aa2d",
      "metadata": {
        "id": "e208aa2d",
        "outputId": "f767eaf4-4f61-46dc-800c-513c43baf822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 2:  really like chocolate\n",
            "Outputs batch 2: touch colonelashi\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
        "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d39e34eb",
      "metadata": {
        "id": "d39e34eb",
        "outputId": "f7bdcb1f-cf0a-4326-e522-0fffd8e8f8b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3626,  6100,   345],\n",
              "        [ 1107,   588, 11311]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "aa9e1274",
      "metadata": {
        "id": "aa9e1274",
        "outputId": "ccd3e3c5-5ff8-44bc-9c3e-65367fba2733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.7566e-06, 2.4166e-05, 2.7499e-05])\n",
            "Text 2: tensor([6.2228e-06, 1.1362e-05, 1.9086e-05])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probs_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probs_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ad6b54ac",
      "metadata": {
        "id": "ad6b54ac"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions( sci_mode=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "18344499",
      "metadata": {
        "id": "18344499",
        "outputId": "5518995b-5415-4759-d857-e6fa3a2475ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-11.7670, -10.6306, -10.5014, -11.9873, -11.3852, -10.8666])\n"
          ]
        }
      ],
      "source": [
        "# Compute logarithm of all token probabilities\n",
        "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
        "print(log_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6b08df10",
      "metadata": {
        "id": "6b08df10",
        "outputId": "35cf08a6-23ea-49a9-bfd9-0629f21e2546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-11.1897)\n",
            "tensor(11.1897)\n"
          ]
        }
      ],
      "source": [
        "avg_log_probs = torch.mean(log_probs)\n",
        "print(avg_log_probs)\n",
        "neg_avg_log_probs = avg_log_probs * -1\n",
        "print(neg_avg_log_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cecc539f",
      "metadata": {
        "id": "cecc539f",
        "outputId": "7f8d629e-236a-498d-c737-26a8fff8416f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0d014ba1",
      "metadata": {
        "id": "0d014ba1",
        "outputId": "cd4bcf3a-8706-4e74-864a-4e0b2b68bc96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6446,  0.2940,  0.0321,  ...,  0.9685,  0.9920, -0.6371],\n",
            "        [ 0.0935,  0.0406,  0.1975,  ..., -0.0280,  0.4254,  0.8512],\n",
            "        [ 0.5289, -0.2928, -0.4853,  ..., -0.5554,  0.7612,  0.2685],\n",
            "        [ 0.3361, -0.2405,  0.1118,  ...,  1.0502,  0.8932,  0.1678],\n",
            "        [ 0.5765,  0.7405,  0.0971,  ..., -0.1873, -0.1705,  1.5469],\n",
            "        [-0.2783, -1.2664, -0.2590,  ..., -1.0272, -0.2844,  0.3250]])\n",
            "tensor([ 3626,  6100,   345,  1107,   588, 11311])\n"
          ]
        }
      ],
      "source": [
        "print(logits_flat)\n",
        "print(targets_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "dd4496e9",
      "metadata": {
        "id": "dd4496e9",
        "outputId": "c8c41205-9366-490f-ef92-6faf67c57776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11.1897)\n"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "da356f73",
      "metadata": {
        "id": "da356f73",
        "outputId": "b96adf24-cd20-49a9-ee31-525dd18beaa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(72378.3828)\n"
          ]
        }
      ],
      "source": [
        "# a more interpretable version of cross entropy --\n",
        "# this is basically the number of tokens the model considers for predicted output\n",
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "xunB7Cr1LcwG",
        "outputId": "48277db5-d774-4dee-e56c-1206caa8e178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "id": "xunB7Cr1LcwG",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca08c055-a5ee-4f41-a5e0-bdadfb144ea8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca08c055-a5ee-4f41-a5e0-bdadfb144ea8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ShortStory (2).txt to ShortStory (2) (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8be5a53c",
      "metadata": {
        "id": "8be5a53c",
        "outputId": "70832346-128e-4011-e9c9-cfab8ac2be40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IF you please, ma'am, dinner is served.”\n",
            "\n",
            "David Ha\n"
          ]
        }
      ],
      "source": [
        "# use the short story from before for training:\n",
        "with open(\"ShortStory (2).txt\", \"r\") as f:\n",
        "    text_data= f.read()\n",
        "\n",
        "print(text_data[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "0ec615ad",
      "metadata": {
        "id": "0ec615ad"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "51a99344",
      "metadata": {
        "id": "51a99344"
      },
      "outputs": [],
      "source": [
        "# separate text into training and validation sets:\n",
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "170dd75f",
      "metadata": {
        "id": "170dd75f",
        "outputId": "35088cbd-d6d8-492d-c7b6-e770ba17ab9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 8192\n",
            "Validation tokens: 768\n",
            "All tokens: 8960\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4eb08b22",
      "metadata": {
        "id": "4eb08b22"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ddf190bd",
      "metadata": {
        "id": "ddf190bd",
        "outputId": "0f7f5ada-b7a0-49b8-9fda-a4c4c7eac6a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device.\n",
            "Training loss: 11.01005744934082\n",
            "Validation loss: 10.99343490600586\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    # Use PyTorch 2.9 or newer for stable mps results\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "53faf58d",
      "metadata": {
        "id": "53faf58d"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4661c458",
      "metadata": {
        "id": "4661c458",
        "outputId": "e1857dfe-170f-4faa-93b5-677ca8f9f2e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.289, Val loss 9.677\n",
            "Ep 1 (Step 000005): Train loss 7.643, Val loss 7.931\n",
            "Ep 1 (Step 000010): Train loss 6.419, Val loss 6.839\n",
            "Ep 1 (Step 000015): Train loss 5.967, Val loss 6.376\n",
            "Every effort moves you.       ”  ” ”  ”  ”      ”  ”   ”  ”   �\n",
            "Ep 2 (Step 000020): Train loss 5.680, Val loss 6.214\n",
            "Ep 2 (Step 000025): Train loss 5.357, Val loss 6.133\n",
            "Ep 2 (Step 000030): Train loss 5.121, Val loss 6.094\n",
            "Every effort moves you. “I. “I,” “I.” “I,” “I,“I“I.“I,“I“I,“\n",
            "Ep 3 (Step 000035): Train loss 4.719, Val loss 6.010\n",
            "Ep 3 (Step 000040): Train loss 4.807, Val loss 6.020\n",
            "Ep 3 (Step 000045): Train loss 4.162, Val loss 5.889\n",
            "Every effort moves you.  ” ” “I“I” “I,“I” he said,“I” he said,” he said,“I; but I have\n",
            "Ep 4 (Step 000050): Train loss 3.900, Val loss 5.809\n",
            "Ep 4 (Step 000055): Train loss 3.688, Val loss 5.847\n",
            "Ep 4 (Step 000060): Train loss 3.550, Val loss 5.821\n",
            "Every effort moves you, and she had the truth.” “I, and she had been.” “I was my play. “I, and I have been the truth. “I know, and, and then,\n",
            "Ep 5 (Step 000065): Train loss 2.941, Val loss 5.788\n",
            "Ep 5 (Step 000070): Train loss 2.847, Val loss 5.817\n",
            "Ep 5 (Step 000075): Train loss 2.410, Val loss 5.794\n",
            "Every effort moves you.” “I,“I don't you.”  “You!“And I have been my own; but I have you.“I,“You know her; but I have\n",
            "Ep 6 (Step 000080): Train loss 2.183, Val loss 5.756\n",
            "Ep 6 (Step 000085): Train loss 2.169, Val loss 5.835\n",
            "Ep 6 (Step 000090): Train loss 1.737, Val loss 5.859\n",
            "Ep 6 (Step 000095): Train loss 1.688, Val loss 5.837\n",
            "Every effort moves you would be; and he said.” “I,“I'm sorry, David, I did you know. “It's the room. “I know.“I don't know.” �\n",
            "Ep 7 (Step 000100): Train loss 1.259, Val loss 5.855\n",
            "Ep 7 (Step 000105): Train loss 1.106, Val loss 5.919\n",
            "Ep 7 (Step 000110): Train loss 1.030, Val loss 5.987\n",
            "Every effort moves you would be a great his lips.” “I was a new purpose, a new play it is done in the world to me, and I have been I haven't!” he said.”  “I\n",
            "Ep 8 (Step 000115): Train loss 0.833, Val loss 6.090\n",
            "Ep 8 (Step 000120): Train loss 0.860, Val loss 6.099\n",
            "Ep 8 (Step 000125): Train loss 0.617, Val loss 6.139\n",
            "Every effort moves you,” she said. “I'm. “I know— in myself.”  “And I loved you for it. You were like the hero out of a play. You hurt me?” �\n",
            "Ep 9 (Step 000130): Train loss 0.580, Val loss 6.204\n",
            "Ep 9 (Step 000135): Train loss 0.476, Val loss 6.229\n",
            "Ep 9 (Step 000140): Train loss 0.463, Val loss 6.316\n",
            "Every effort moves you, and man in his lips with a movement that was grotesquely theatrical.”  “Years ago, and looked back over his shoulder into the only condition I make; but I stick to it. The tiny, to help her own\n",
            "Ep 10 (Step 000145): Train loss 0.339, Val loss 6.383\n",
            "Ep 10 (Step 000150): Train loss 0.327, Val loss 6.453\n",
            "Ep 10 (Step 000155): Train loss 0.260, Val loss 6.429\n",
            "Every effort moves you,” she said firmly. “And his play is worth the risk. And who knows, Miss O'Connor—Mrs. Hardy—may rise to the occasion. At least, I shall do all that I can to help her.\n"
          ]
        }
      ],
      "source": [
        "# Note:\n",
        "# Uncomment the following code to calculate the execution time\n",
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# Uncomment the following code to show the execution time\n",
        "# end_time = time.time()\n",
        "# execution_time_minutes = (end_time - start_time) / 60\n",
        "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
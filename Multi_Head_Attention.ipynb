{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCRUV++Vi3LgSTPRAuHbls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teelch0/Data-Mining/blob/main/Multi_Head_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "R6F5bIkZ0lZ4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi-head attention\n",
        "#multiple causal attentions stuck together\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat( [ head(x) for head in self.heads], dim= -1)"
      ],
      "metadata": {
        "id": "kXvlzHCp1Dh0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "R-vPRhRcziX6"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`,\n",
        "        # this will result in errors in the mask creation further below.\n",
        "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
        "        # do not exceed `context_length` before reaching this forward method.\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length= 5\n",
        "d_in= 10"
      ],
      "metadata": {
        "id": "dPAa42-UCgGE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start with creating inputs\n",
        "inputs= torch.nn.Embedding(5, 10)\n",
        "inputs= inputs.weight\n",
        "inputs= inputs.data\n",
        "print(inputs.shape)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c5_LyIh0utf",
        "outputId": "f97bb445-05f6-44df-85ad-7bbcbe51c8f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3500,  0.7753, -1.1204,  1.4635, -0.1660, -2.0281,  0.4279, -1.2608,\n",
              "          0.8427, -0.6945],\n",
              "        [ 0.6027,  0.5035,  2.2409, -0.6299, -0.7292,  1.2694, -0.5501, -0.0203,\n",
              "          1.5254,  0.1577],\n",
              "        [-1.7250,  1.2829,  0.9096,  0.5401,  0.0137,  0.1198, -0.6908, -1.0769,\n",
              "         -0.4205, -0.8605],\n",
              "        [-0.0182, -0.0219, -0.2350,  0.5616, -0.2769, -0.1936,  0.6561, -0.5074,\n",
              "          1.5030,  0.7483],\n",
              "        [ 0.5468,  0.2581,  0.6384,  0.4816,  1.2872, -0.1513, -0.0416, -0.0716,\n",
              "          1.1854,  1.0654]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stack your inputs into a tensor using torch\n",
        "batches = torch.stack( (inputs, inputs), dim=0)\n",
        "print(batches.shape)\n",
        "batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e_ooTpY3Oz4",
        "outputId": "92decd06-10c3-43b9-85bf-8eaa2cc3e750"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3500,  0.7753, -1.1204,  1.4635, -0.1660, -2.0281,  0.4279,\n",
              "          -1.2608,  0.8427, -0.6945],\n",
              "         [ 0.6027,  0.5035,  2.2409, -0.6299, -0.7292,  1.2694, -0.5501,\n",
              "          -0.0203,  1.5254,  0.1577],\n",
              "         [-1.7250,  1.2829,  0.9096,  0.5401,  0.0137,  0.1198, -0.6908,\n",
              "          -1.0769, -0.4205, -0.8605],\n",
              "         [-0.0182, -0.0219, -0.2350,  0.5616, -0.2769, -0.1936,  0.6561,\n",
              "          -0.5074,  1.5030,  0.7483],\n",
              "         [ 0.5468,  0.2581,  0.6384,  0.4816,  1.2872, -0.1513, -0.0416,\n",
              "          -0.0716,  1.1854,  1.0654]],\n",
              "\n",
              "        [[-0.3500,  0.7753, -1.1204,  1.4635, -0.1660, -2.0281,  0.4279,\n",
              "          -1.2608,  0.8427, -0.6945],\n",
              "         [ 0.6027,  0.5035,  2.2409, -0.6299, -0.7292,  1.2694, -0.5501,\n",
              "          -0.0203,  1.5254,  0.1577],\n",
              "         [-1.7250,  1.2829,  0.9096,  0.5401,  0.0137,  0.1198, -0.6908,\n",
              "          -1.0769, -0.4205, -0.8605],\n",
              "         [-0.0182, -0.0219, -0.2350,  0.5616, -0.2769, -0.1936,  0.6561,\n",
              "          -0.5074,  1.5030,  0.7483],\n",
              "         [ 0.5468,  0.2581,  0.6384,  0.4816,  1.2872, -0.1513, -0.0416,\n",
              "          -0.0716,  1.1854,  1.0654]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining some variables that will be used\n",
        "d_out= 6\n",
        "num_heads= 3 #make sure d_out is perfectly divisible by num_heads\n",
        "head_dim= 2\n",
        "b= 2"
      ],
      "metadata": {
        "id": "CQW4Lti79fK-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial creation of the query and key matrices\n",
        "W_query= nn.Linear(d_in, d_out, bias= False)\n",
        "W_key= nn.Linear(d_in, d_out, bias= False)"
      ],
      "metadata": {
        "id": "VwDqp-F28g-v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fill keys with batches\n",
        "keys= W_key(batches)\n",
        "print(keys.shape)\n",
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssCja2Qh3qPe",
        "outputId": "5d5ea91f-5c19-40bb-86d4-76ad8dd3e8ef"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1691,  0.1188,  0.7480,  0.6117,  0.9782, -0.4419],\n",
              "         [-1.3669,  0.1143, -0.2911,  0.0660, -1.1708, -0.4260],\n",
              "         [-0.7013,  0.4421,  1.1728,  0.4512, -0.0262,  0.4880],\n",
              "         [-0.2076,  0.1596,  0.0519,  0.3650, -0.0022, -0.4062],\n",
              "         [ 0.3004,  0.2110,  0.2574, -0.4897,  0.0420,  0.0453]],\n",
              "\n",
              "        [[ 0.1691,  0.1188,  0.7480,  0.6117,  0.9782, -0.4419],\n",
              "         [-1.3669,  0.1143, -0.2911,  0.0660, -1.1708, -0.4260],\n",
              "         [-0.7013,  0.4421,  1.1728,  0.4512, -0.0262,  0.4880],\n",
              "         [-0.2076,  0.1596,  0.0519,  0.3650, -0.0022, -0.4062],\n",
              "         [ 0.3004,  0.2110,  0.2574, -0.4897,  0.0420,  0.0453]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fill queries with batches\n",
        "queries = W_query(batches)\n",
        "print(queries.shape)\n",
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJaYMf-Q_V36",
        "outputId": "9fe38d77-461e-40c4-8263-77fd16d3da00"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5409, -0.3635, -0.0140, -1.2837, -0.0203,  0.7939],\n",
              "         [ 0.3729,  0.7044, -0.2444,  0.8769, -0.2299,  0.1697],\n",
              "         [-1.1598, -0.5548, -0.5169, -0.1720,  0.6657, -0.2489],\n",
              "         [ 0.3508,  0.5328, -0.0522,  0.2179, -0.5714,  0.6954],\n",
              "         [-0.0082,  0.2895,  0.1432,  0.3992,  0.1078,  0.2411]],\n",
              "\n",
              "        [[-0.5409, -0.3635, -0.0140, -1.2837, -0.0203,  0.7939],\n",
              "         [ 0.3729,  0.7044, -0.2444,  0.8769, -0.2299,  0.1697],\n",
              "         [-1.1598, -0.5548, -0.5169, -0.1720,  0.6657, -0.2489],\n",
              "         [ 0.3508,  0.5328, -0.0522,  0.2179, -0.5714,  0.6954],\n",
              "         [-0.0082,  0.2895,  0.1432,  0.3992,  0.1078,  0.2411]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change the view to satisfy number of heads\n",
        "keys= keys.view(b, context_length , num_heads, head_dim)\n",
        "print(keys.shape)\n",
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo3euR2__6IT",
        "outputId": "29cc66b2-8f70-44d7-b30e-992741858306"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 3, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1691,  0.1188],\n",
              "          [ 0.7480,  0.6117],\n",
              "          [ 0.9782, -0.4419]],\n",
              "\n",
              "         [[-1.3669,  0.1143],\n",
              "          [-0.2911,  0.0660],\n",
              "          [-1.1708, -0.4260]],\n",
              "\n",
              "         [[-0.7013,  0.4421],\n",
              "          [ 1.1728,  0.4512],\n",
              "          [-0.0262,  0.4880]],\n",
              "\n",
              "         [[-0.2076,  0.1596],\n",
              "          [ 0.0519,  0.3650],\n",
              "          [-0.0022, -0.4062]],\n",
              "\n",
              "         [[ 0.3004,  0.2110],\n",
              "          [ 0.2574, -0.4897],\n",
              "          [ 0.0420,  0.0453]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1691,  0.1188],\n",
              "          [ 0.7480,  0.6117],\n",
              "          [ 0.9782, -0.4419]],\n",
              "\n",
              "         [[-1.3669,  0.1143],\n",
              "          [-0.2911,  0.0660],\n",
              "          [-1.1708, -0.4260]],\n",
              "\n",
              "         [[-0.7013,  0.4421],\n",
              "          [ 1.1728,  0.4512],\n",
              "          [-0.0262,  0.4880]],\n",
              "\n",
              "         [[-0.2076,  0.1596],\n",
              "          [ 0.0519,  0.3650],\n",
              "          [-0.0022, -0.4062]],\n",
              "\n",
              "         [[ 0.3004,  0.2110],\n",
              "          [ 0.2574, -0.4897],\n",
              "          [ 0.0420,  0.0453]]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the view of queries to satisfy number of heads\n",
        "queries= queries.view(b, context_length , num_heads, head_dim)\n",
        "print(queries.shape)\n",
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxInP87NC6cP",
        "outputId": "936b49d1-0a28-4691-f055-9b22b80b318c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 3, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.5409, -0.3635],\n",
              "          [-0.0140, -1.2837],\n",
              "          [-0.0203,  0.7939]],\n",
              "\n",
              "         [[ 0.3729,  0.7044],\n",
              "          [-0.2444,  0.8769],\n",
              "          [-0.2299,  0.1697]],\n",
              "\n",
              "         [[-1.1598, -0.5548],\n",
              "          [-0.5169, -0.1720],\n",
              "          [ 0.6657, -0.2489]],\n",
              "\n",
              "         [[ 0.3508,  0.5328],\n",
              "          [-0.0522,  0.2179],\n",
              "          [-0.5714,  0.6954]],\n",
              "\n",
              "         [[-0.0082,  0.2895],\n",
              "          [ 0.1432,  0.3992],\n",
              "          [ 0.1078,  0.2411]]],\n",
              "\n",
              "\n",
              "        [[[-0.5409, -0.3635],\n",
              "          [-0.0140, -1.2837],\n",
              "          [-0.0203,  0.7939]],\n",
              "\n",
              "         [[ 0.3729,  0.7044],\n",
              "          [-0.2444,  0.8769],\n",
              "          [-0.2299,  0.1697]],\n",
              "\n",
              "         [[-1.1598, -0.5548],\n",
              "          [-0.5169, -0.1720],\n",
              "          [ 0.6657, -0.2489]],\n",
              "\n",
              "         [[ 0.3508,  0.5328],\n",
              "          [-0.0522,  0.2179],\n",
              "          [-0.5714,  0.6954]],\n",
              "\n",
              "         [[-0.0082,  0.2895],\n",
              "          [ 0.1432,  0.3992],\n",
              "          [ 0.1078,  0.2411]]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transpose keys to prepare for matrix multiplication\n",
        "keys_T= keys.transpose(1,2)\n",
        "print(keys_T.shape)\n",
        "keys_T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIEfhYbiEkt7",
        "outputId": "3544d973-755b-4896-d11d-cac67e7f2f6f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1691,  0.1188],\n",
              "          [-1.3669,  0.1143],\n",
              "          [-0.7013,  0.4421],\n",
              "          [-0.2076,  0.1596],\n",
              "          [ 0.3004,  0.2110]],\n",
              "\n",
              "         [[ 0.7480,  0.6117],\n",
              "          [-0.2911,  0.0660],\n",
              "          [ 1.1728,  0.4512],\n",
              "          [ 0.0519,  0.3650],\n",
              "          [ 0.2574, -0.4897]],\n",
              "\n",
              "         [[ 0.9782, -0.4419],\n",
              "          [-1.1708, -0.4260],\n",
              "          [-0.0262,  0.4880],\n",
              "          [-0.0022, -0.4062],\n",
              "          [ 0.0420,  0.0453]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1691,  0.1188],\n",
              "          [-1.3669,  0.1143],\n",
              "          [-0.7013,  0.4421],\n",
              "          [-0.2076,  0.1596],\n",
              "          [ 0.3004,  0.2110]],\n",
              "\n",
              "         [[ 0.7480,  0.6117],\n",
              "          [-0.2911,  0.0660],\n",
              "          [ 1.1728,  0.4512],\n",
              "          [ 0.0519,  0.3650],\n",
              "          [ 0.2574, -0.4897]],\n",
              "\n",
              "         [[ 0.9782, -0.4419],\n",
              "          [-1.1708, -0.4260],\n",
              "          [-0.0262,  0.4880],\n",
              "          [-0.0022, -0.4062],\n",
              "          [ 0.0420,  0.0453]]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transpose queries\n",
        "queries_T= queries.transpose(1,2)\n",
        "print(queries_T.shape)\n",
        "queries_T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEPor_QaFnKW",
        "outputId": "15495fd4-983c-47ba-8443-d7ab8f47b458"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.5409, -0.3635],\n",
              "          [ 0.3729,  0.7044],\n",
              "          [-1.1598, -0.5548],\n",
              "          [ 0.3508,  0.5328],\n",
              "          [-0.0082,  0.2895]],\n",
              "\n",
              "         [[-0.0140, -1.2837],\n",
              "          [-0.2444,  0.8769],\n",
              "          [-0.5169, -0.1720],\n",
              "          [-0.0522,  0.2179],\n",
              "          [ 0.1432,  0.3992]],\n",
              "\n",
              "         [[-0.0203,  0.7939],\n",
              "          [-0.2299,  0.1697],\n",
              "          [ 0.6657, -0.2489],\n",
              "          [-0.5714,  0.6954],\n",
              "          [ 0.1078,  0.2411]]],\n",
              "\n",
              "\n",
              "        [[[-0.5409, -0.3635],\n",
              "          [ 0.3729,  0.7044],\n",
              "          [-1.1598, -0.5548],\n",
              "          [ 0.3508,  0.5328],\n",
              "          [-0.0082,  0.2895]],\n",
              "\n",
              "         [[-0.0140, -1.2837],\n",
              "          [-0.2444,  0.8769],\n",
              "          [-0.5169, -0.1720],\n",
              "          [-0.0522,  0.2179],\n",
              "          [ 0.1432,  0.3992]],\n",
              "\n",
              "         [[-0.0203,  0.7939],\n",
              "          [-0.2299,  0.1697],\n",
              "          [ 0.6657, -0.2489],\n",
              "          [-0.5714,  0.6954],\n",
              "          [ 0.1078,  0.2411]]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiply transposed queries by newly transposed keys for attention scores\n",
        "attn_scores= queries_T @ keys_T.transpose(2, 3)\n",
        "print(attn_scores.shape)\n",
        "attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KXxaTmTGlzR",
        "outputId": "d5e67f1c-7fea-4dec-d4a1-fe30944825ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-1.3464e-01,  6.9784e-01,  2.1856e-01,  5.4249e-02, -2.3919e-01],\n",
              "          [ 1.4673e-01, -4.2929e-01,  4.9914e-02,  3.5004e-02,  2.6066e-01],\n",
              "          [-2.6200e-01,  1.5220e+00,  5.6800e-01,  1.5218e-01, -4.6546e-01],\n",
              "          [ 1.2262e-01, -4.1868e-01, -1.0446e-02,  1.2211e-02,  2.1782e-01],\n",
              "          [ 3.3008e-02,  4.4287e-02,  1.3374e-01,  4.7900e-02,  5.8627e-02]],\n",
              "\n",
              "         [[-7.9567e-01, -8.0605e-02, -5.9559e-01, -4.6923e-01,  6.2499e-01],\n",
              "          [ 3.5357e-01,  1.2900e-01,  1.0897e-01,  3.0735e-01, -4.9232e-01],\n",
              "          [-4.9187e-01,  1.3913e-01, -6.8389e-01, -8.9642e-02, -4.8789e-02],\n",
              "          [ 9.4263e-02,  2.9577e-02,  3.7099e-02,  7.6834e-02, -1.2016e-01],\n",
              "          [ 3.5126e-01, -1.5351e-02,  3.4803e-01,  1.5313e-01, -1.5862e-01]],\n",
              "\n",
              "         [[-3.7064e-01, -3.1444e-01,  3.8796e-01, -3.2246e-01,  3.5115e-02],\n",
              "          [-2.9993e-01,  1.9692e-01,  8.8852e-02, -6.8451e-02, -1.9695e-03],\n",
              "          [ 7.6120e-01, -6.7346e-01, -1.3887e-01,  9.9641e-02,  1.6692e-02],\n",
              "          [-8.6621e-01,  3.7273e-01,  3.5433e-01, -2.8126e-01,  7.5044e-03],\n",
              "          [-1.0421e-03, -2.2896e-01,  1.1483e-01, -9.8176e-02,  1.5453e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.3464e-01,  6.9784e-01,  2.1856e-01,  5.4249e-02, -2.3919e-01],\n",
              "          [ 1.4673e-01, -4.2929e-01,  4.9914e-02,  3.5004e-02,  2.6066e-01],\n",
              "          [-2.6200e-01,  1.5220e+00,  5.6800e-01,  1.5218e-01, -4.6546e-01],\n",
              "          [ 1.2262e-01, -4.1868e-01, -1.0446e-02,  1.2211e-02,  2.1782e-01],\n",
              "          [ 3.3008e-02,  4.4287e-02,  1.3374e-01,  4.7900e-02,  5.8627e-02]],\n",
              "\n",
              "         [[-7.9567e-01, -8.0605e-02, -5.9559e-01, -4.6923e-01,  6.2499e-01],\n",
              "          [ 3.5357e-01,  1.2900e-01,  1.0897e-01,  3.0735e-01, -4.9232e-01],\n",
              "          [-4.9187e-01,  1.3913e-01, -6.8389e-01, -8.9642e-02, -4.8789e-02],\n",
              "          [ 9.4263e-02,  2.9577e-02,  3.7099e-02,  7.6834e-02, -1.2016e-01],\n",
              "          [ 3.5126e-01, -1.5351e-02,  3.4803e-01,  1.5313e-01, -1.5862e-01]],\n",
              "\n",
              "         [[-3.7064e-01, -3.1444e-01,  3.8796e-01, -3.2246e-01,  3.5115e-02],\n",
              "          [-2.9993e-01,  1.9692e-01,  8.8852e-02, -6.8451e-02, -1.9695e-03],\n",
              "          [ 7.6120e-01, -6.7346e-01, -1.3887e-01,  9.9641e-02,  1.6692e-02],\n",
              "          [-8.6621e-01,  3.7273e-01,  3.5433e-01, -2.8126e-01,  7.5044e-03],\n",
              "          [-1.0421e-03, -2.2896e-01,  1.1483e-01, -9.8176e-02,  1.5453e-02]]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a mask to avoid overfitting\n",
        "mask= torch.triu(torch.ones(context_length, context_length), diagonal= 1)\n",
        "print(mask.shape)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2SQE9JPMnN9",
        "outputId": "0fb05364-6c0e-4896-b4a1-7dde807e3d87"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converted to boolean (true or false)\n",
        "mask_bool= mask.bool()[:context_length, :context_length]\n",
        "print(mask_bool.shape)\n",
        "mask_bool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nRrxOHEWrRy",
        "outputId": "cde4a16b-ac84-407d-9f09-7a5ff630ef8c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True,  True],\n",
              "        [False, False,  True,  True,  True],\n",
              "        [False, False, False,  True,  True],\n",
              "        [False, False, False, False,  True],\n",
              "        [False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fill attention scores\n",
        "attn_scores.masked_fill_(mask_bool, -torch.inf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS55omnUboXp",
        "outputId": "91cf2af5-e510-4bf9-ba34-cf12656fcea8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-1.3464e-01,        -inf,        -inf,        -inf,        -inf],\n",
              "          [ 1.4673e-01, -4.2929e-01,        -inf,        -inf,        -inf],\n",
              "          [-2.6200e-01,  1.5220e+00,  5.6800e-01,        -inf,        -inf],\n",
              "          [ 1.2262e-01, -4.1868e-01, -1.0446e-02,  1.2211e-02,        -inf],\n",
              "          [ 3.3008e-02,  4.4287e-02,  1.3374e-01,  4.7900e-02,  5.8627e-02]],\n",
              "\n",
              "         [[-7.9567e-01,        -inf,        -inf,        -inf,        -inf],\n",
              "          [ 3.5357e-01,  1.2900e-01,        -inf,        -inf,        -inf],\n",
              "          [-4.9187e-01,  1.3913e-01, -6.8389e-01,        -inf,        -inf],\n",
              "          [ 9.4263e-02,  2.9577e-02,  3.7099e-02,  7.6834e-02,        -inf],\n",
              "          [ 3.5126e-01, -1.5351e-02,  3.4803e-01,  1.5313e-01, -1.5862e-01]],\n",
              "\n",
              "         [[-3.7064e-01,        -inf,        -inf,        -inf,        -inf],\n",
              "          [-2.9993e-01,  1.9692e-01,        -inf,        -inf,        -inf],\n",
              "          [ 7.6120e-01, -6.7346e-01, -1.3887e-01,        -inf,        -inf],\n",
              "          [-8.6621e-01,  3.7273e-01,  3.5433e-01, -2.8126e-01,        -inf],\n",
              "          [-1.0421e-03, -2.2896e-01,  1.1483e-01, -9.8176e-02,  1.5453e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.3464e-01,        -inf,        -inf,        -inf,        -inf],\n",
              "          [ 1.4673e-01, -4.2929e-01,        -inf,        -inf,        -inf],\n",
              "          [-2.6200e-01,  1.5220e+00,  5.6800e-01,        -inf,        -inf],\n",
              "          [ 1.2262e-01, -4.1868e-01, -1.0446e-02,  1.2211e-02,        -inf],\n",
              "          [ 3.3008e-02,  4.4287e-02,  1.3374e-01,  4.7900e-02,  5.8627e-02]],\n",
              "\n",
              "         [[-7.9567e-01,        -inf,        -inf,        -inf,        -inf],\n",
              "          [ 3.5357e-01,  1.2900e-01,        -inf,        -inf,        -inf],\n",
              "          [-4.9187e-01,  1.3913e-01, -6.8389e-01,        -inf,        -inf],\n",
              "          [ 9.4263e-02,  2.9577e-02,  3.7099e-02,  7.6834e-02,        -inf],\n",
              "          [ 3.5126e-01, -1.5351e-02,  3.4803e-01,  1.5313e-01, -1.5862e-01]],\n",
              "\n",
              "         [[-3.7064e-01,        -inf,        -inf,        -inf,        -inf],\n",
              "          [-2.9993e-01,  1.9692e-01,        -inf,        -inf,        -inf],\n",
              "          [ 7.6120e-01, -6.7346e-01, -1.3887e-01,        -inf,        -inf],\n",
              "          [-8.6621e-01,  3.7273e-01,  3.5433e-01, -2.8126e-01,        -inf],\n",
              "          [-1.0421e-03, -2.2896e-01,  1.1483e-01, -9.8176e-02,  1.5453e-02]]]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check shapes one last time\n",
        "print(mask_bool.shape)\n",
        "print(attn_scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znp0Jo7Ic9rt",
        "outputId": "1a216051-2cea-4fc0-9b7f-ab6d1095ffdc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 5])\n",
            "torch.Size([2, 3, 5, 5])\n"
          ]
        }
      ]
    }
  ]
}